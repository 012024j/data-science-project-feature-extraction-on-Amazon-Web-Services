#  Fruits! - Traitement Big Data sur le Cloud

## Contexte du projet

Ce projet s'inscrit dans le cadre d'une mission en tant que **Data Scientist** au sein de la start-up **Fruits!**, une entreprise de l'AgriTech qui d√©veloppe des solutions innovantes pour la reconnaissance et la classification de fruits √† partir d‚Äôimages.

Dans le but de sensibiliser le grand public √† la biodiversit√© fruiti√®re et de poser les bases de futurs robots cueilleurs intelligents, **Fruits!** d√©veloppe une application mobile permettant √† l'utilisateur de prendre une photo d‚Äôun fruit et d‚Äôobtenir instantan√©ment des informations sur celui-ci.

---

## Objectifs

- R√©aliser un **traitement Big Data** sur un **jeu de donn√©es volumineux d‚Äôimages de fruits**.
- Migrer le pipeline local vers une **infrastructure Cloud distribu√©e** (AWS).
- Exploiter **PySpark** et des outils comme **EMR, S3, EC2, IAM, EMR Studio** pour un traitement efficace.
- Appliquer une **r√©duction de dimension** par **ACP** (PCA).
- Pr√©parer les donn√©es pour un futur pipeline de classification d‚Äôimages.

---

## Donn√©es

- **Dataset utilis√©** : [Fruits-360](https://www.kaggle.com/datasets/moltean/fruits)
- **Nombre d‚Äôimages** : 138 704
- **Nombre de classes de fruits** : 206

---

## Architecture Big Data (AWS)

| Composant | Description |
|----------|-------------|
| **S3** | Stockage distribu√© pour les images d'entr√©e et les r√©sultats (format parquet) |
| **EMR** | Traitement des donn√©es avec PySpark sur cluster distribu√© |
| **EC2** | Instances m5.xlarge pour ex√©cuter les workers Spark |
| **EMR Studio** | Interface JupyterLab connect√©e au cluster pour d√©veloppement interactif |
| **IAM** | Gestion des r√¥les et s√©curit√© RGPD (r√©gion `eu-west-3`) |

---

## Pipeline de traitement PySpark

1. **Chargement des images** depuis S3 + redimensionnement (224x224x3)
2. **Extraction de caract√©ristiques visuelles** avec le mod√®le pr√©-entra√Æn√© **MobileNetV2** (embeddings 1280-dim)
3. **Diffusion des poids du mod√®le** √† tous les workers Spark (broadcast)
4. **Stockage des embeddings** en **format Parquet** sur S3
5. **R√©duction de dimension** avec une **ACP** (20 composantes) pour simplification et pr√©vision
6. **Sauvegarde des r√©sultats** r√©duits sur S3

---

## Technologies utilis√©es

- **PySpark**
- **AWS (S3, EMR, EMR Studio, EC2, IAM)**
- **Parquet**
- **TensorFlow / MobileNetV2**
- **PCA (ACP)** pour r√©duction de dimension

---

## R√©sultats

- Traitement distribu√© ex√©cut√© avec succ√®s sur EMR
- Embeddings visuels extraits et compress√©s
- R√©duction √† 6 composantes expliquant 98% de la variance
- Pipeline √©volutif, pr√™t √† √™tre connect√© √† un mod√®le de classification

---

##  Perspectives

- Tester d'autres mod√®les d'extraction (ResNet, EfficientNet)
- Entra√Æner un mod√®le de classification (MLP, SVM, etc.)
- D√©velopper une interface mobile (Streamlit, API)
- Int√©grer une surveillance automatis√©e (logs, m√©triques, drift)

---

## üõ°Ô∏è RGPD

Toutes les ressources AWS ont √©t√© d√©ploy√©es en **r√©gion europ√©enne** (eu-west-3) pour garantir la conformit√© RGPD. Aucun traitement de donn√©es personnelles.

---


---

## Auteure

 **Oumou Faye**  
Projet r√©alis√© dans le cadre de la formation **Data Scientist**  
Mentor : Medina Hadjem  





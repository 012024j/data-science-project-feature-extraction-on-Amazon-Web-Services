#  Fruits! - Traitement Big Data sur le Cloud

## ğŸ“ Contexte du projet

Ce projet s'inscrit dans le cadre d'une mission en tant que **Data Scientist** au sein de la start-up **Fruits!**, une entreprise de l'AgriTech qui dÃ©veloppe des solutions innovantes pour la reconnaissance et la classification de fruits Ã  partir dâ€™images.

Dans le but de sensibiliser le grand public Ã  la biodiversitÃ© fruitiÃ¨re et de poser les bases de futurs robots cueilleurs intelligents, **Fruits!** dÃ©veloppe une application mobile permettant Ã  l'utilisateur de prendre une photo dâ€™un fruit et dâ€™obtenir instantanÃ©ment des informations sur celui-ci.

---

## ğŸ¯ Objectifs

- RÃ©aliser un **traitement Big Data** sur un **jeu de donnÃ©es volumineux dâ€™images de fruits**.
- Migrer le pipeline local vers une **infrastructure Cloud distribuÃ©e** (AWS).
- Exploiter **PySpark** et des outils comme **EMR, S3, EC2, IAM, EMR Studio** pour un traitement efficace.
- Appliquer une **rÃ©duction de dimension** par **ACP** (PCA).
- PrÃ©parer les donnÃ©es pour un futur pipeline de classification dâ€™images.

---

## ğŸ—‚ï¸ DonnÃ©es

- ğŸ“ **Dataset utilisÃ©** : [Fruits-360](https://www.kaggle.com/datasets/moltean/fruits)
- ğŸ–¼ï¸ **Nombre dâ€™images** : 138 704
- ğŸ **Nombre de classes de fruits** : 206

---

## ğŸ—ï¸ Architecture Big Data (AWS)

| Composant | Description |
|----------|-------------|
| **S3** | Stockage distribuÃ© pour les images d'entrÃ©e et les rÃ©sultats (format parquet) |
| **EMR** | Traitement des donnÃ©es avec PySpark sur cluster distribuÃ© |
| **EC2** | Instances m5.xlarge pour exÃ©cuter les workers Spark |
| **EMR Studio** | Interface JupyterLab connectÃ©e au cluster pour dÃ©veloppement interactif |
| **IAM** | Gestion des rÃ´les et sÃ©curitÃ© RGPD (rÃ©gion `eu-west-3`) |

---

## ğŸ” Pipeline de traitement PySpark

1. **Chargement des images** depuis S3 + redimensionnement (224x224x3)
2. **Extraction de caractÃ©ristiques visuelles** avec le modÃ¨le prÃ©-entraÃ®nÃ© **MobileNetV2** (embeddings 1280-dim)
3. **Diffusion des poids du modÃ¨le** Ã  tous les workers Spark (broadcast)
4. **Stockage des embeddings** en **format Parquet** sur S3
5. **RÃ©duction de dimension** avec une **ACP** (20 composantes) pour simplification et prÃ©vision
6. **Sauvegarde des rÃ©sultats** rÃ©duits sur S3

---

## âš™ï¸ Technologies utilisÃ©es

- ğŸ”¥ **PySpark**
- â˜ï¸ **AWS (S3, EMR, EMR Studio, EC2, IAM)**
- ğŸ“¦ **Parquet**
- ğŸ§  **TensorFlow / MobileNetV2**
- ğŸ“Š **PCA (ACP)** pour rÃ©duction de dimension

---

## ğŸ“ˆ RÃ©sultats

- âœ”ï¸ Traitement distribuÃ© exÃ©cutÃ© avec succÃ¨s sur EMR
- âœ”ï¸ Embeddings visuels extraits et compressÃ©s
- âœ”ï¸ RÃ©duction Ã  6 composantes expliquant 98% de la variance
- âœ”ï¸ Pipeline Ã©volutif, prÃªt Ã  Ãªtre connectÃ© Ã  un modÃ¨le de classification

---

##  Perspectives

- ğŸ” Tester d'autres modÃ¨les d'extraction (ResNet, EfficientNet)
- ğŸ§  EntraÃ®ner un modÃ¨le de classification (MLP, SVM, etc.)
- ğŸ“² DÃ©velopper une interface mobile (Streamlit, API)
- ğŸ” IntÃ©grer une surveillance automatisÃ©e (logs, mÃ©triques, drift)

---

## ğŸ›¡ï¸ RGPD

Toutes les ressources AWS ont Ã©tÃ© dÃ©ployÃ©es en **rÃ©gion europÃ©enne** (eu-west-3) pour garantir la conformitÃ© RGPD. Aucun traitement de donnÃ©es personnelles.

---


---

## ğŸ™‹ Auteure

 **Oumou Faye**  
Projet rÃ©alisÃ© dans le cadre de la formation **Data Scientist**  
Mentor : Medina Hadjem  




